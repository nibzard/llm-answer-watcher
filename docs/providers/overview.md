# Provider Overview

LLM Answer Watcher supports 6 major LLM providers with a unified interface. Choose providers based on cost, performance, and feature requirements.

## Supported Providers

| Provider | Models | Cost Range | Web Search | Best For |
|----------|--------|------------|------------|----------|
| **OpenAI** | gpt-4o-mini, gpt-4o, more | $0.15-$10/1M tokens | ✅ Yes | General use, cost-effective |
| **Anthropic** | Claude 3.5 Haiku, Sonnet, Opus | $0.80-$75/1M tokens | ❌ No | High-quality responses |
| **Mistral** | mistral-large, mistral-small | $0.30-$2/1M tokens | ❌ No | European alternative |
| **X.AI (Grok)** | grok-beta, grok-2, grok-3 | $2-$25/1M tokens | ❌ No | X platform integration |
| **Google** | Gemini 2.0 Flash | $0.075-$0.30/1M tokens | ❌ No | Low-cost option |
| **Perplexity** | Sonar, Sonar Pro | $1-$15/1M tokens | ✅ Built-in | Grounded responses |

## Quick Configuration

### Single Provider

```yaml
run_settings:
  models:
    - provider: "openai"
      model_name: "gpt-4o-mini"
      env_api_key: "OPENAI_API_KEY"
```

### Multiple Providers

```yaml
run_settings:
  models:
    - provider: "openai"
      model_name: "gpt-4o-mini"
      env_api_key: "OPENAI_API_KEY"

    - provider: "anthropic"
      model_name: "claude-3-5-haiku-20241022"
      env_api_key: "ANTHROPIC_API_KEY"

    - provider: "perplexity"
      model_name: "sonar-pro"
      env_api_key: "PERPLEXITY_API_KEY"
```

## Provider Selection Guide

### By Budget

**Ultra Low Cost (<$0.005 per query):**

- Google Gemini 2.0 Flash
- OpenAI gpt-4o-mini

**Low Cost ($0.005-0.01 per query):**

- Mistral mistral-small
- Anthropic Claude 3.5 Haiku

**Medium Cost ($0.01-0.05 per query):**

- OpenAI gpt-4o
- Anthropic Claude 3.5 Sonnet
- Perplexity Sonar Pro

**High Cost (>$0.05 per query):**

- Anthropic Claude 3.5 Opus
- Grok grok-3
- OpenAI gpt-4-turbo

### By Feature

**Web Search Required:**

- ✅ OpenAI (with tools configuration)
- ✅ Perplexity (built-in)

**No Web Search:**

- Anthropic, Mistral, Grok, Google

**Grounded Responses:**

- ✅ Perplexity (best)
- ✅ OpenAI with web search

**High Quality:**

- Anthropic Claude 3.5 Sonnet/Opus
- OpenAI gpt-4o
- Perplexity Sonar Pro

**Fast Response:**

- OpenAI gpt-4o-mini
- Google Gemini Flash
- Mistral mistral-small

### By Use Case

**Cost-Optimized Monitoring:**

```yaml
models:
  - provider: "openai"
    model_name: "gpt-4o-mini"
```

**High-Quality Analysis:**

```yaml
models:
  - provider: "anthropic"
    model_name: "claude-3-5-sonnet-20241022"
```

**Multi-Provider Comparison:**

```yaml
models:
  - provider: "openai"
    model_name: "gpt-4o-mini"
  - provider: "anthropic"
    model_name: "claude-3-5-haiku-20241022"
  - provider: "perplexity"
    model_name: "sonar"
```

**Web Search Required:**

```yaml
models:
  - provider: "perplexity"
    model_name: "sonar-pro"
```

## API Key Setup

### OpenAI

```bash
export OPENAI_API_KEY=sk-your-openai-key-here
```

Get key: https://platform.openai.com/api-keys

### Anthropic

```bash
export ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here
```

Get key: https://console.anthropic.com/

### Mistral

```bash
export MISTRAL_API_KEY=your-mistral-key-here
```

Get key: https://console.mistral.ai/

### X.AI (Grok)

```bash
export XAI_API_KEY=xai-your-grok-key-here
```

Get key: https://console.x.ai/

### Google Gemini

```bash
export GOOGLE_API_KEY=AIza-your-google-api-key-here
```

Get key: https://aistudio.google.com/apikey

### Perplexity

```bash
export PERPLEXITY_API_KEY=pplx-your-perplexity-key-here
```

Get key: https://www.perplexity.ai/settings/api

## Provider Comparison

### Response Quality

**Best to Good:**

1. Anthropic Claude 3.5 Opus
2. Anthropic Claude 3.5 Sonnet
3. OpenAI gpt-4o
4. Perplexity Sonar Pro
5. Mistral mistral-large
6. Grok grok-3
7. Anthropic Claude 3.5 Haiku
8. OpenAI gpt-4o-mini
9. Google Gemini 2.0 Flash
10. Mistral mistral-small

### Cost Efficiency

**Best value (quality per dollar):**

1. OpenAI gpt-4o-mini
2. Google Gemini 2.0 Flash
3. Anthropic Claude 3.5 Haiku
4. Mistral mistral-small
5. Perplexity Sonar

### Speed

**Fastest to Slowest:**

1. Google Gemini Flash
2. OpenAI gpt-4o-mini
3. Mistral models
4. Perplexity Sonar
5. Anthropic Haiku
6. OpenAI gpt-4o
7. Anthropic Sonnet
8. Grok models
9. Anthropic Opus

## Rate Limits

Default rate limits (check provider docs for current limits):

| Provider | Requests/Min | Tokens/Min |
|----------|--------------|------------|
| OpenAI | 500 | 90,000 |
| Anthropic | 50 | 100,000 |
| Mistral | 5-60 | Varies |
| X.AI | 60 | 120,000 |
| Google | 15 | 32,000 |
| Perplexity | 20 | Varies |

**Recommendation:** Add delays between queries if hitting rate limits:

```yaml
run_settings:
  delay_between_queries: 2  # seconds
```

## Provider-Specific Features

### OpenAI

- ✅ Web search via tools
- ✅ Function calling
- ✅ JSON mode
- ✅ Vision support (not used)

See [OpenAI Provider](openai.md)

### Anthropic

- ✅ Extended context (200K tokens)
- ✅ Function calling
- ✅ JSON mode
- ✅ Thinking mode (not used)

See [Anthropic Provider](anthropic.md)

### Mistral

- ✅ European data residency
- ✅ Function calling
- ✅ JSON mode
- ✅ Competitive pricing

See [Mistral Provider](mistral.md)

### X.AI (Grok)

- ✅ X platform integration
- ✅ OpenAI-compatible API
- ✅ Real-time information
- ⚠️ Limited model selection

See [Grok Provider](grok.md)

### Google

- ✅ Very low cost
- ✅ Fast responses
- ✅ Long context (1M tokens)
- ⚠️ Newer platform

See [Google Provider](google.md)

### Perplexity

- ✅ Built-in web search
- ✅ Grounded responses
- ✅ Citations included
- ✅ Real-time information
- ⚠️ Request fees (not in cost estimate)

See [Perplexity Provider](perplexity.md)

## Multi-Provider Strategies

### Strategy 1: Cost vs Quality

Cheap model for volume, expensive for quality:

```yaml
models:
  # High volume, low cost
  - provider: "openai"
    model_name: "gpt-4o-mini"

  # Occasional high-quality check
  - provider: "anthropic"
    model_name: "claude-3-5-sonnet-20241022"
    enabled_for: ["critical-intent"]
```

### Strategy 2: Provider Diversity

Avoid single-provider dependency:

```yaml
models:
  - provider: "openai"
    model_name: "gpt-4o-mini"

  - provider: "anthropic"
    model_name: "claude-3-5-haiku-20241022"

  - provider: "google"
    model_name: "gemini-2.0-flash-exp"
```

### Strategy 3: Web Search + Standard

```yaml
models:
  # Standard queries
  - provider: "openai"
    model_name: "gpt-4o-mini"

  # Web-search enabled
  - provider: "perplexity"
    model_name: "sonar-pro"
```

## Common Issues

### API Key Errors

```
❌ API key not found: OPENAI_API_KEY
```

**Solution:**

```bash
export OPENAI_API_KEY=sk-your-key-here
```

### Rate Limit Exceeded

```
⚠️ Rate limit exceeded for openai/gpt-4o-mini
```

**Solutions:**

1. Add delay: `delay_between_queries: 2`
2. Reduce concurrent requests
3. Upgrade API tier

### Model Not Found

```
❌ Model not found: gpt-4-mini
```

**Solution:** Use correct model name: `gpt-4o-mini`

See provider docs for valid models.

### Authentication Failed

```
❌ Authentication failed: Invalid API key
```

**Solutions:**

1. Check key spelling
2. Regenerate key at provider console
3. Verify key has correct permissions

## Next Steps

<div class="grid cards" markdown>

-   :simple-openai: **OpenAI**

    ---

    Complete OpenAI provider guide

    [OpenAI Provider →](openai.md)

-   :simple-anthropic: **Anthropic**

    ---

    Claude models documentation

    [Anthropic Provider →](anthropic.md)

-   :material-robot: **Perplexity**

    ---

    Grounded LLMs with web search

    [Perplexity Provider →](perplexity.md)

-   :material-cog: **Configuration**

    ---

    Model configuration details

    [Model Config →](../user-guide/configuration/models.md)

</div>
