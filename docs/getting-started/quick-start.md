# Quick Start

Get LLM Answer Watcher up and running in 5 minutes.

## Prerequisites

Before you begin, ensure you have:

- **Python 3.12 or 3.13** installed
- **API keys** for at least one LLM provider (OpenAI recommended for getting started)
- **Basic terminal knowledge**

## Installation

### Option 1: Using uv (Recommended)

[uv](https://github.com/astral-sh/uv) is a fast Python package installer and resolver.

```bash
# Clone the repository
git clone https://github.com/nibzard/llm-answer-watcher.git
cd llm-answer-watcher

# Install dependencies
uv sync

# Activate virtual environment (optional, uv handles this automatically)
source .venv/bin/activate
```

### Option 2: Using pip

```bash
# Clone the repository
git clone https://github.com/nibzard/llm-answer-watcher.git
cd llm-answer-watcher

# Create virtual environment
python3.12 -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install in development mode
pip install -e .
```

## Set Up API Keys

LLM Answer Watcher uses environment variables for API keys. Set up at least one:

```bash
# OpenAI (recommended for getting started)
export OPENAI_API_KEY=sk-your-openai-key-here

# Optional: Add more providers
export ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here
export MISTRAL_API_KEY=mistral-your-key-here
export XAI_API_KEY=xai-your-grok-key-here
export GOOGLE_API_KEY=AIza-your-google-api-key-here
export PERPLEXITY_API_KEY=pplx-your-perplexity-key-here
```

!!! tip "Persistent API Keys"
    Create a `.env` file to persist your keys:
    ```bash
    echo "OPENAI_API_KEY=sk-your-key" > .env
    source .env
    ```

    Add `.env` to your `.gitignore` to avoid accidentally committing secrets!

## Your First Run

LLM Answer Watcher includes example configurations you can use immediately.

### 1. Choose an Example Config

The repository includes several example configs in the `examples/` directory:

- `watcher.config.yaml` - Basic configuration with OpenAI
- `steel-dev-quick.config.yaml` - Quick test configuration
- `watcher-with-web-search.config.yaml` - Configuration with web search enabled

### 2. Run the Tool

```bash
llm-answer-watcher run --config examples/watcher.config.yaml
```

### 3. View the Output

You'll see a beautiful progress display:

```
üîç Running LLM Answer Watcher...
‚îú‚îÄ‚îÄ Configuration loaded from examples/watcher.config.yaml
‚îú‚îÄ‚îÄ Query 1/2: "What are the best email warmup tools?"
‚îú‚îÄ‚îÄ Query 2/2: "Compare the top email warmup tools"
‚îú‚îÄ‚îÄ Models: OpenAI gpt-4o-mini
‚îú‚îÄ‚îÄ Brands: 2 monitored, 4 competitors
‚îî‚îÄ‚îÄ Output: ./output/2025-11-05T14-30-00Z/

‚úÖ Queries completed: 2/2
üí∞ Total cost: $0.0042
üìä Report: ./output/2025-11-05T14-30-00Z/report.html
```

### 4. Explore Results

Open the HTML report in your browser:

```bash
open ./output/2025-11-05T14-30-00Z/report.html
# Or on Linux:
xdg-open ./output/2025-11-05T14-30-00Z/report.html
```

The report shows:

- **Summary**: Total costs, queries completed, brands found
- **Brand Mentions**: Which brands appeared in each response
- **Rank Distribution**: Visual charts of ranking positions
- **Raw Responses**: Full LLM outputs for inspection

## Understanding the Output

Each run creates a timestamped directory with:

```
output/2025-11-05T14-30-00Z/
‚îú‚îÄ‚îÄ run_meta.json                    # Run summary and stats
‚îú‚îÄ‚îÄ report.html                      # Interactive HTML report
‚îú‚îÄ‚îÄ intent_*_raw_*.json             # Raw LLM responses
‚îú‚îÄ‚îÄ intent_*_parsed_*.json          # Extracted brand mentions
‚îî‚îÄ‚îÄ intent_*_error_*.json           # Error details (if any)
```

All data is also stored in a SQLite database at `./output/watcher.db` for historical analysis.

## What's Next?

Now that you've run your first monitoring job, here are suggested next steps:

### Create Your Own Configuration

Create `my-watcher.config.yaml`:

```yaml
run_settings:
  output_dir: "./output"
  sqlite_db_path: "./output/watcher.db"

  models:
    - provider: "openai"
      model_name: "gpt-4o-mini"
      env_api_key: "OPENAI_API_KEY"

brands:
  mine:
    - "YourBrand"
    - "YourBrand.io"

  competitors:
    - "CompetitorA"
    - "CompetitorB"
    - "IndustryTool"

intents:
  - id: "best-tools-in-category"
    prompt: "What are the best [your category] tools?"

  - id: "comparison-query"
    prompt: "Compare the top [your category] tools"
```

Then run:

```bash
llm-answer-watcher run --config my-watcher.config.yaml
```

### Explore More Features

<div class="grid cards" markdown>

-   :material-cog: **Configuration Deep Dive**

    ---

    Learn about all configuration options

    [Configuration Guide ‚Üí](../user-guide/configuration/overview.md)

-   :material-chart-bar: **Multiple Providers**

    ---

    Add Anthropic, Mistral, Grok, and more

    [Provider Guide ‚Üí](../providers/overview.md)

-   :material-database: **Query Your Data**

    ---

    Use SQL to analyze historical trends

    [Data Analytics ‚Üí](../data-analytics/sqlite-database.md)

-   :material-robot: **Automate Monitoring**

    ---

    Set up scheduled runs with cron or GitHub Actions

    [Automation Guide ‚Üí](../user-guide/usage/automation.md)

</div>

## Common Issues

### "Command not found: llm-answer-watcher"

Make sure you've activated your virtual environment:

```bash
source .venv/bin/activate  # On macOS/Linux
# or
.venv\Scripts\activate     # On Windows
```

### "Configuration error: API key not found"

Ensure your API keys are exported:

```bash
echo $OPENAI_API_KEY  # Should print your key
```

If empty, export it:

```bash
export OPENAI_API_KEY=sk-your-key-here
```

### "ImportError: No module named 'llm_answer_watcher'"

Re-install the package:

```bash
pip install -e .
```

## Getting Help

- **Documentation**: Browse this site for comprehensive guides
- **Examples**: Check the `examples/` directory in the repository
- **Issues**: [Report bugs or ask questions](https://github.com/nibzard/llm-answer-watcher/issues)
- **Contributing**: [Read the contributing guide](../contributing/development-setup.md)

---

Ready to dive deeper? Continue to the [Installation Guide](installation.md) for more installation options.
