# LLM Answer Watcher - Sample Output

This directory contains sample output generated by **LLM Answer Watcher** to demonstrate what the tool produces when monitoring brand mentions in LLM responses.

## üìã Overview

This sample output shows results from a run that monitored how different LLMs talk about email warmup tools and sales engagement platforms, specifically tracking mentions of **Warmly/Warmly.io** versus competitors like **HubSpot, Instantly, Apollo.io,** and others.

**Run Details:**
- **Run ID:** `2025-11-02T10-15-30Z`
- **Timestamp:** November 2, 2025 at 10:15:30 UTC
- **Models Used:** OpenAI gpt-4o-mini, Anthropic claude-3-5-haiku-20241022
- **Total Cost:** $0.0187
- **Total Queries:** 6 (3 intents √ó 2 models)

## üìÅ File Structure

```
examples/sample_output/
‚îú‚îÄ‚îÄ README.md                           # This file - explanation of the sample output
‚îú‚îÄ‚îÄ run_meta.json                       # Summary of the entire run with costs and statistics
‚îú‚îÄ‚îÄ intent_best-email-warmup-tools_raw_openai_gpt-4o-mini.json      # Raw LLM response
‚îú‚îÄ‚îÄ intent_best-email-warmup-tools_parsed_openai_gpt-4o-mini.json   # Extracted brand mentions
‚îú‚îÄ‚îÄ intent_sales-engagement-platforms_raw_anthropic_claude-3-5-haiku-20241022.json    # Raw LLM response
‚îú‚îÄ‚îÄ intent_sales-engagement-platforms_parsed_anthropic_claude-3-5-haiku-20241022.json # Extracted brand mentions
‚îî‚îÄ‚îÄ report.html                         # Human-readable HTML report
```

## üìä Key Results Summary

### Brand Performance
- **Your Brand (Warmly/Warmly.io):** 3 total mentions
  - Ranked #1 for "best email warmup tools" query
  - Ranked #5 for "sales engagement platforms" query
- **Competitors:** 11 total mentions across all queries
  - HubSpot: 4 mentions (strongest competitor)
  - Instantly: 3 mentions
  - Lemwarm: 2 mentions
  - Apollo.io: 1 mention
  - Woodpecker: 1 mention

### Cost Breakdown
- **Total Cost:** $0.0187
- **Total Tokens:** 2,739 (1,847 prompt + 892 completion)
- **Average Cost per Query:** ~$0.003

## üìÑ File Explanations

### 1. `run_meta.json`
**Purpose:** Master summary of the entire run
**Key Contents:**
- Run metadata (ID, timestamp, configuration)
- Cost and token usage statistics
- Success/failure rates
- Brand mention summary
- File locations and technical details

**Use Case:** Programmatic access to run results, API responses, cost tracking

### 2. Raw Response Files (`intent_*_raw_*.json`)
**Purpose:** Verbatim LLM responses with metadata
**Key Contents:**
- Complete LLM response text
- Token usage and cost breakdown
- API response time and processing metrics
- Retry count and error information

**Example: `intent_best-email-warmup-tools_raw_openai_gpt-4o-mini.json`
```json
{
  "prompt": "What are the best email warmup tools?",
  "raw_response": "Based on my research and user feedback...",
  "usage": {
    "prompt_tokens": 312,
    "completion_tokens": 189,
    "total_tokens": 501,
    "cost_usd": 0.0012
  }
}
```

**Use Case:** Content analysis, debugging, response quality assessment

### 3. Parsed Response Files (`intent_*_parsed_*.json`)
**Purpose:** Structured brand mention extraction and ranking
**Key Contents:**
- Brand mentions with position and context
- Confidence scores for each detection
- Rank positions for all mentioned brands
- Separation of your brands vs competitors

**Example Snippet:**
```json
{
  "brands_detected": [
    {
      "normalized_name": "Warmly.io",
      "rank_position": 1,
      "confidence_score": 1.0,
      "context_snippets": ["**Warmly.io** - A comprehensive email warmup solution..."]
    }
  ],
  "my_brands_mentioned": ["Warmly.io"],
  "competitor_brands_mentioned": ["Instantly", "Lemwarm", "HubSpot"]
}
```

**Use Case:** Competitive analysis, trend tracking, automated reporting

### 4. `report.html`
**Purpose:** Human-readable visual report
**Features:**
- Executive summary with key metrics
- Brand mention comparison
- Ranking visualization
- Sample LLM responses
- Technical details and metadata

**Use Case:** Stakeholder presentations, quick insights, manual review

## üîç What This Sample Demonstrates

### 1. **Word-Boundary Matching**
The tool accurately identifies brand mentions using word boundaries:
- ‚úÖ "Warmly" matches correctly
- ‚úÖ "HubSpot" matches in "Use HubSpot daily"
- ‚ùå Prevents false positives (e.g., "hub" doesn't match in "GitHub")

### 2. **Multi-Provider Support**
Shows consistent extraction across different LLM providers:
- OpenAI gpt-4o-mini responses
- Anthropic claude-3-5-haiku responses
- Unified JSON structure regardless of provider

### 3. **Rank Extraction**
Automatically extracts numerical rankings from LLM responses:
- "1. Warmly.io" ‚Üí Rank 1
- "2. Instantly" ‚Üí Rank 2
- Handles both numbered and unnumbered lists

### 4. **Cost Tracking**
Detailed cost breakdown by model and query:
- Token usage monitoring
- Per-query cost calculation
- Total spend tracking

### 5. **Dual-Mode Output**
Both machine-readable (JSON) and human-readable (HTML) formats:
- JSON for automation and APIs
- HTML for presentations and manual review

## üöÄ How to Generate Your Own Output

### 1. **Setup Configuration**
```bash
cp examples/watcher.config.yaml my-config.yaml
# Edit my-config.yaml with your brands and competitors
```

### 2. **Set Up API Keys**
```bash
cp examples/.env.example .env
# Edit .env with your actual API keys
```

### 3. **Run the Tool**
```bash
# Human mode (default) - Rich console output
llm-answer-watcher run --config my-config.yaml

# Agent mode - Structured JSON output
llm-answer-watcher run --config my-config.yaml --format json

# Automation mode - No prompts, JSON output
llm-answer-watcher run --config my-config.yaml --yes --format json
```

### 4. **Find Your Results**
Results are saved to timestamped directories:
```
output/
‚îî‚îÄ‚îÄ 2025-11-02T10-15-30Z/    # Your run directory
    ‚îú‚îÄ‚îÄ run_meta.json
    ‚îú‚îÄ‚îÄ intent_*_raw_*.json
    ‚îú‚îÄ‚îÄ intent_*_parsed_*.json
    ‚îî‚îÄ‚îÄ report.html
```

## üìà Analysis Insights from This Sample

### Competitive Positioning
- **Strength:** Warmly.io ranked #1 for email warmup tools query
- **Opportunity:** Lower ranking (#5) for sales engagement platforms
- **Market Landscape:** HubSpot appears as strongest competitor with most mentions

### Content Strategy Insights
- LLMs consistently mention "comprehensive solution" and "automated features" for Warmly.io
- Competitors are often mentioned for specific features (user-friendly interface, agency features)
- Opportunity to strengthen sales engagement platform positioning

### Technical Performance
- 100% success rate (6/6 queries successful)
- Fast response times (1.4-2.1 seconds per query)
- Cost-effective averaging (~$0.003 per query)

## üõ†Ô∏è Integration Examples

### Python Integration
```python
import json

# Load run summary
with open('run_meta.json') as f:
    run_summary = json.load(f)

# Access brand mentions
my_mentions = run_summary['results']['mentions_found']['mine']
competitor_mentions = run_summary['results']['mentions_found']['competitors']

print(f"Your brands mentioned {my_mentions['total_mentions']} times")
print(f"Competitors mentioned {competitor_mentions['total_mentions']} times")
```

### Shell Script Monitoring
```bash
#!/bin/bash
# Extract total cost from latest run
latest_run=$(ls -t ../output/ | head -n 1)
cost=$(jq -r '.results.total_cost_usd' "../output/$latest_run/run_meta.json")
echo "Latest run cost: $cost"

# Alert if cost exceeds threshold
if (( $(echo "$cost > 0.10" | bc -l) )); then
    echo "WARNING: High cost detected: $cost"
fi
```

## üîê Security Notes

- **No API Keys:** This sample output contains no actual API keys or sensitive data
- **Mock Data:** Responses are realistic examples, not actual LLM outputs
- **Safe to Share:** All files in this directory are safe to share and commit
- **Production Safety:** Real runs automatically redact sensitive information from logs

## üìû Questions?

For more information about LLM Answer Watcher:
- **Documentation:** See project README.md
- **Configuration:** See examples/watcher.config.yaml
- **Issues:** Report bugs or feature requests on GitHub
- **Community:** Join discussions in project issues