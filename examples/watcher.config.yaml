run_settings:
  output_dir: "./output"
  sqlite_db_path: "./output/watcher.db"

  # Maximum concurrent API requests (default: 10)
  # Conservative limit respects provider rate limits while enabling parallelism
  # Based on research: OpenAI ~5-10, Anthropic limited, Gemini ~3 per key
  # Increase for higher quotas, decrease if hitting rate limits
  max_concurrent_requests: 10

  models:
    - provider: "openai"
      model_name: "gpt-4o-mini"
      env_api_key: "OPENAI_API_KEY"
      system_prompt: "openai/gpt-4-default"  # Optional: Uses provider default if not specified

    # Google Gemini with Google Search grounding
    # NOTE: Google uses 'google_search: {}' format (dictionary with tool name as key)
    # This differs from OpenAI's format: 'type: "web_search"' (typed specification)
    # Each provider has different API requirements - config does direct passthrough
    - provider: "google"
      model_name: "gemini-2.0-flash-exp"
      env_api_key: "GEMINI_API_KEY"
      system_prompt: "google/gemini-grounding"
      tools:
        - google_search: {}  # Google API format for Search grounding

    # - provider: "anthropic"
    #   model_name: "claude-3-5-haiku-20241022"
    #   env_api_key: "ANTHROPIC_API_KEY"
    #   # No system_prompt specified - will use anthropic/default.json

    # - provider: "mistral"
    #   model_name: "mistral-large-latest"
    #   env_api_key: "MISTRAL_API_KEY"
    #   # No system_prompt specified - will use mistral/default.json

  use_llm_rank_extraction: false

# Extraction settings (optional - enables function calling for better accuracy)
# If not specified, defaults to regex-based extraction (backward compatible)
extraction_settings:
  extraction_model:
    provider: "openai"
    model_name: "gpt-4o-mini"  # Fast + cheap model optimized for extraction
    env_api_key: "OPENAI_API_KEY"
    system_prompt: "openai/extraction-default"  # Specialized extraction prompt

  # Extraction method: function_calling (recommended), regex, or hybrid
  method: "function_calling"

  # Fall back to regex if function calling fails
  fallback_to_regex: true

  # Minimum confidence threshold (0.0-1.0) for accepting function results
  min_confidence: 0.7

  # Extract sentiment and context for each brand mention (default: true)
  enable_sentiment_analysis: true

  # Classify user query intent before extraction (default: true)
  enable_intent_classification: true

brands:
  mine:
    - "Lemwarm"
    - "Lemlist"

  competitors:
    - "Instantly"
    - "Apollo.io"
    - "Woodpecker"
    - "Mailwarm"
    - "Warmup Inbox"

intents:
  - id: "best-email-warmup-tools"
    prompt: "What are the best email warmup tools?"

  - id: "email-warmup-comparison"
    prompt: "Compare the top email warmup tools for improving deliverability"