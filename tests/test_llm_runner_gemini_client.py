"""
Tests for llm_runner.gemini_client module.

Tests cover:
- GeminiClient initialization and validation
- Successful API calls with proper response parsing
- Retry logic on transient failures (429, 5xx)
- Immediate failure on non-retryable errors (401, 400, 404)
- Token usage extraction and cost calculation
- Error handling and logging (without logging API keys)
- Edge cases (empty responses, malformed JSON, missing fields)
- Safety filter handling (blocked content)
"""

import logging

import httpx
import pytest
from freezegun import freeze_time

from llm_answer_watcher.llm_runner.gemini_client import (
    GEMINI_API_BASE_URL,
    MAX_PROMPT_LENGTH,
    GeminiClient,
)
from llm_answer_watcher.llm_runner.models import LLMResponse

# Skip all Gemini tests temporarily - mock setup needs work
pytestmark = pytest.mark.skip(
    reason="Gemini mock setup WIP - httpx mock registration issues"
)

# Test system prompt for all tests
TEST_SYSTEM_PROMPT = "You are a test assistant."


class TestGeminiClientInit:
    """Test suite for GeminiClient initialization."""

    def test_init_success(self):
        """Test successful client initialization."""
        client = GeminiClient(
            "gemini-2.0-flash-exp", "AIza-test123", TEST_SYSTEM_PROMPT
        )

        assert client.model_name == "gemini-2.0-flash-exp"
        assert client.api_key == "AIza-test123"
        assert client.system_prompt == TEST_SYSTEM_PROMPT

    def test_init_different_model(self):
        """Test initialization with different model."""
        client = GeminiClient("gemini-1.5-pro", "AIza-prod456", TEST_SYSTEM_PROMPT)

        assert client.model_name == "gemini-1.5-pro"
        assert client.api_key == "AIza-prod456"

    def test_init_empty_model_name(self):
        """Test that empty model_name raises ValueError."""
        with pytest.raises(ValueError, match="model_name cannot be empty"):
            GeminiClient("", "AIza-test123", TEST_SYSTEM_PROMPT)

    def test_init_whitespace_model_name(self):
        """Test that whitespace-only model_name raises ValueError."""
        with pytest.raises(ValueError, match="model_name cannot be empty"):
            GeminiClient("   ", "AIza-test123", TEST_SYSTEM_PROMPT)

    def test_init_empty_api_key(self):
        """Test that empty api_key raises ValueError."""
        with pytest.raises(ValueError, match="api_key cannot be empty"):
            GeminiClient("gemini-2.0-flash-exp", "", TEST_SYSTEM_PROMPT)

    def test_init_whitespace_api_key(self):
        """Test that whitespace-only api_key raises ValueError."""
        with pytest.raises(ValueError, match="api_key cannot be empty"):
            GeminiClient("gemini-2.0-flash-exp", "   ", TEST_SYSTEM_PROMPT)

    def test_init_empty_system_prompt(self):
        """Test that empty system_prompt raises ValueError."""
        with pytest.raises(ValueError, match="system_prompt cannot be empty"):
            GeminiClient("gemini-2.0-flash-exp", "AIza-test123", "")

    def test_init_whitespace_system_prompt(self):
        """Test that whitespace-only system_prompt raises ValueError."""
        with pytest.raises(ValueError, match="system_prompt cannot be empty"):
            GeminiClient("gemini-2.0-flash-exp", "AIza-test123", "   ")

    def test_init_logs_model_not_api_key(self, caplog):
        """Test that initialization logs model name but NEVER logs API key."""
        caplog.set_level(logging.INFO)

        GeminiClient("gemini-2.0-flash-exp", "AIza-secret123", TEST_SYSTEM_PROMPT)

        # Should log model name
        assert "gemini-2.0-flash-exp" in caplog.text

        # Should NEVER log API key
        assert "AIza-secret123" not in caplog.text
        assert "secret" not in caplog.text

    def test_init_with_tools_logs_warning(self, caplog):
        """Test that initialization with tools logs a warning."""
        caplog.set_level(logging.WARNING)

        tools = [{"type": "web_search"}]
        GeminiClient(
            "gemini-2.0-flash-exp",
            "AIza-test123",
            TEST_SYSTEM_PROMPT,
            tools=tools,
        )

        # Should log warning about tools not being supported
        assert "Tools are not currently supported" in caplog.text
        assert "gemini-2.0-flash-exp" in caplog.text


class TestGenerateAnswerSuccess:
    """Test suite for successful Gemini API calls."""

    @freeze_time("2025-11-02T08:30:45Z")
    def test_generate_answer_success(self, httpx_mock):
        """Test successful API call with complete response."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        # Mock successful Gemini API response
        httpx_mock.add_response(
            method="POST",
            url=api_url,
            json={
                "candidates": [
                    {
                        "content": {
                            "parts": [
                                {
                                    "text": "Based on market research, the top CRM tools are Salesforce, HubSpot, and Zoho."
                                }
                            ],
                            "role": "model",
                        },
                        "finishReason": "STOP",
                    }
                ],
                "usageMetadata": {
                    "promptTokenCount": 100,
                    "candidatesTokenCount": 50,
                    "totalTokenCount": 150,
                },
            },
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)
        response = client.generate_answer("What are the best CRM tools?")

        # Verify response structure
        assert isinstance(response, LLMResponse)
        assert (
            response.answer_text
            == "Based on market research, the top CRM tools are Salesforce, HubSpot, and Zoho."
        )
        assert response.tokens_used == 150
        assert response.prompt_tokens == 100
        assert response.completion_tokens == 50
        assert response.cost_usd == 0.0  # Free during experimental preview
        assert response.provider == "google"
        assert response.model_name == model_name
        assert response.timestamp_utc == "2025-11-02T08:30:45Z"
        assert response.web_search_results is None
        assert response.web_search_count == 0

    def test_generate_answer_sends_correct_payload(self, httpx_mock):
        """Test that API request includes system instruction and correct structure."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        httpx_mock.add_response(
            method="POST",
            url=api_url,
            json={
                "candidates": [
                    {
                        "content": {
                            "parts": [{"text": "Test response"}],
                            "role": "model",
                        },
                        "finishReason": "STOP",
                    }
                ],
                "usageMetadata": {"totalTokenCount": 100},
            },
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)
        client.generate_answer("Test prompt")

        # Verify request was made
        request = httpx_mock.get_request()
        assert request is not None

        # Verify request structure for Gemini API
        import json

        payload = request.read()
        data = json.loads(payload)

        assert "contents" in data
        assert len(data["contents"]) == 1
        assert data["contents"][0]["role"] == "user"
        assert data["contents"][0]["parts"][0]["text"] == "Test prompt"

        assert "systemInstruction" in data
        assert data["systemInstruction"]["parts"][0]["text"] == TEST_SYSTEM_PROMPT

        assert "generationConfig" in data
        assert data["generationConfig"]["temperature"] == 0.7

    def test_generate_answer_sends_api_key_in_params(self, httpx_mock):
        """Test that API request includes API key in query parameters."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        httpx_mock.add_response(
            method="POST",
            url=api_url,
            json={
                "candidates": [
                    {
                        "content": {"parts": [{"text": "Test"}], "role": "model"},
                        "finishReason": "STOP",
                    }
                ],
                "usageMetadata": {"totalTokenCount": 10},
            },
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)
        client.generate_answer("Test")

        # Verify API key in query parameters
        request = httpx_mock.get_request()
        assert "key=AIza-test123" in str(request.url)
        assert request.headers["Content-Type"] == "application/json"

    def test_generate_answer_large_response(self, httpx_mock):
        """Test handling of large response with high token count."""
        model_name = "gemini-1.5-pro"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        large_content = "A" * 10000
        httpx_mock.add_response(
            method="POST",
            url=api_url,
            json={
                "candidates": [
                    {
                        "content": {
                            "parts": [{"text": large_content}],
                            "role": "model",
                        },
                        "finishReason": "STOP",
                    }
                ],
                "usageMetadata": {
                    "promptTokenCount": 10000,
                    "candidatesTokenCount": 40000,
                    "totalTokenCount": 50000,
                },
            },
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)
        response = client.generate_answer("Generate large text")

        assert response.answer_text == large_content
        assert response.tokens_used == 50000
        assert response.prompt_tokens == 10000
        assert response.completion_tokens == 40000

    def test_generate_answer_with_cost_calculation(self, httpx_mock):
        """Test cost calculation for paid Gemini model."""
        model_name = "gemini-1.5-flash"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        httpx_mock.add_response(
            method="POST",
            url=api_url,
            json={
                "candidates": [
                    {
                        "content": {"parts": [{"text": "Response"}], "role": "model"},
                        "finishReason": "STOP",
                    }
                ],
                "usageMetadata": {
                    "promptTokenCount": 1000,
                    "candidatesTokenCount": 500,
                    "totalTokenCount": 1500,
                },
            },
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)
        response = client.generate_answer("Test")

        # Cost: (1000 * $0.075/1M) + (500 * $0.30/1M) = $0.000075 + $0.000150 = $0.000225
        assert response.cost_usd > 0
        assert response.cost_usd == pytest.approx(0.000225, abs=0.000001)


class TestGenerateAnswerValidation:
    """Test suite for input validation."""

    def test_generate_answer_empty_prompt(self):
        """Test that empty prompt raises ValueError."""
        client = GeminiClient(
            "gemini-2.0-flash-exp", "AIza-test123", TEST_SYSTEM_PROMPT
        )

        with pytest.raises(ValueError, match="Prompt cannot be empty"):
            client.generate_answer("")

    def test_generate_answer_whitespace_prompt(self):
        """Test that whitespace-only prompt raises ValueError."""
        client = GeminiClient(
            "gemini-2.0-flash-exp", "AIza-test123", TEST_SYSTEM_PROMPT
        )

        with pytest.raises(ValueError, match="Prompt cannot be empty"):
            client.generate_answer("   \n\t  ")


class TestPromptLengthValidation:
    """Test suite for prompt length validation in Gemini client."""

    def test_generate_answer_accepts_normal_prompt(self, httpx_mock):
        """Normal-length prompts should be accepted."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        # Mock successful response
        httpx_mock.add_response(
            method="POST",
            url=api_url,
            json={
                "candidates": [
                    {
                        "content": {
                            "parts": [{"text": "Test response"}],
                            "role": "model",
                        },
                        "finishReason": "STOP",
                    }
                ],
                "usageMetadata": {"totalTokenCount": 100},
            },
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)
        # Test with a reasonable prompt (< 100k chars)
        prompt = "What are the best email warmup tools?" * 100  # ~4000 chars
        response = client.generate_answer(prompt)

        assert response.answer_text == "Test response"
        assert len(httpx_mock.get_requests()) == 1

    def test_generate_answer_accepts_max_length_prompt(self, httpx_mock):
        """Prompts exactly at max length should be accepted."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        # Mock successful response
        httpx_mock.add_response(
            method="POST",
            url=api_url,
            json={
                "candidates": [
                    {
                        "content": {
                            "parts": [{"text": "Test response"}],
                            "role": "model",
                        },
                        "finishReason": "STOP",
                    }
                ],
                "usageMetadata": {"totalTokenCount": 100},
            },
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)
        prompt = "a" * MAX_PROMPT_LENGTH
        response = client.generate_answer(prompt)

        # Should not raise ValueError for length
        assert response.answer_text == "Test response"

    def test_generate_answer_rejects_over_limit_prompt(self):
        """Prompts over max length should raise ValueError."""
        client = GeminiClient(
            "gemini-2.0-flash-exp", "AIza-test123", TEST_SYSTEM_PROMPT
        )
        prompt = "a" * (MAX_PROMPT_LENGTH + 1)

        with pytest.raises(ValueError, match=r"Prompt exceeds maximum length"):
            client.generate_answer(prompt)

    def test_generate_answer_rejects_very_long_prompt(self):
        """Very long prompts should raise ValueError with correct count."""
        client = GeminiClient(
            "gemini-2.0-flash-exp", "AIza-test123", TEST_SYSTEM_PROMPT
        )
        prompt = "a" * (MAX_PROMPT_LENGTH * 2)

        with pytest.raises(ValueError, match=r"200,000 characters"):
            client.generate_answer(prompt)

    def test_generate_answer_error_message_shows_actual_length(self):
        """Error message should show actual received length."""
        client = GeminiClient(
            "gemini-2.0-flash-exp", "AIza-test123", TEST_SYSTEM_PROMPT
        )
        prompt = "a" * (MAX_PROMPT_LENGTH + 5000)

        with pytest.raises(ValueError) as exc_info:
            client.generate_answer(prompt)

        error_msg = str(exc_info.value)
        assert "105,000 characters" in error_msg
        assert "100,000 characters" in error_msg
        assert "shorten your prompt" in error_msg


class TestGenerateAnswerNonRetryableErrors:
    """Test suite for non-retryable errors (401, 400, 404)."""

    def test_generate_answer_401_unauthorized(self, httpx_mock):
        """Test that 401 error raises RuntimeError immediately (no retry)."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        httpx_mock.add_response(
            method="POST",
            url=api_url,
            status_code=401,
            json={"error": {"message": "Invalid API key"}},
        )

        client = GeminiClient(model_name, "AIza-invalid", TEST_SYSTEM_PROMPT)

        with pytest.raises(RuntimeError, match="non-retryable"):
            client.generate_answer("Test")

        # Verify only one request was made (no retry)
        assert len(httpx_mock.get_requests()) == 1

    def test_generate_answer_400_bad_request(self, httpx_mock):
        """Test that 400 error raises RuntimeError immediately (no retry)."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        httpx_mock.add_response(
            method="POST",
            url=api_url,
            status_code=400,
            json={"error": {"message": "Invalid request format"}},
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)

        with pytest.raises(RuntimeError, match="non-retryable"):
            client.generate_answer("Test")

    def test_generate_answer_404_not_found(self, httpx_mock):
        """Test that 404 error raises RuntimeError immediately (no retry)."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        httpx_mock.add_response(
            method="POST",
            url=api_url,
            status_code=404,
            json={"error": {"message": "Model not found"}},
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)

        with pytest.raises(RuntimeError, match="non-retryable"):
            client.generate_answer("Test")


class TestGenerateAnswerRetryableErrors:
    """Test suite for retryable errors (429, 5xx) with retry logic."""

    def test_generate_answer_429_rate_limit_then_success(self, httpx_mock):
        """Test that 429 error is retried and succeeds on second attempt."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        # First call: rate limit
        httpx_mock.add_response(
            method="POST",
            url=api_url,
            status_code=429,
            json={"error": {"message": "Rate limit exceeded"}},
        )

        # Second call: success
        httpx_mock.add_response(
            method="POST",
            url=api_url,
            status_code=200,
            json={
                "candidates": [
                    {
                        "content": {
                            "parts": [{"text": "Success after retry"}],
                            "role": "model",
                        },
                        "finishReason": "STOP",
                    }
                ],
                "usageMetadata": {"totalTokenCount": 50},
            },
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)
        response = client.generate_answer("Test")

        assert response.answer_text == "Success after retry"
        assert len(httpx_mock.get_requests()) == 2  # Two attempts

    def test_generate_answer_500_server_error_then_success(self, httpx_mock):
        """Test that 500 error is retried and succeeds."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        # First call: server error
        httpx_mock.add_response(
            method="POST",
            url=api_url,
            status_code=500,
            json={"error": {"message": "Internal server error"}},
        )

        # Second call: success
        httpx_mock.add_response(
            method="POST",
            url=api_url,
            status_code=200,
            json={
                "candidates": [
                    {
                        "content": {"parts": [{"text": "Recovered"}], "role": "model"},
                        "finishReason": "STOP",
                    }
                ],
                "usageMetadata": {"totalTokenCount": 30},
            },
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)
        response = client.generate_answer("Test")

        assert response.answer_text == "Recovered"

    def test_generate_answer_502_bad_gateway_exhausts_retries(self, httpx_mock):
        """Test that 502 exhausts retries and raises error."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        # Mock 3 failed attempts (max retries from retry_config)
        for _ in range(3):
            httpx_mock.add_response(
                method="POST",
                url=api_url,
                status_code=502,
                json={"error": {"message": "Bad gateway"}},
            )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)

        with pytest.raises(httpx.HTTPStatusError):
            client.generate_answer("Test")


class TestGenerateAnswerResponseParsing:
    """Test suite for response parsing edge cases."""

    def test_generate_answer_missing_candidates(self, httpx_mock):
        """Test that missing 'candidates' raises RuntimeError."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        httpx_mock.add_response(
            method="POST",
            url=api_url,
            json={"usageMetadata": {"totalTokenCount": 10}},  # Missing 'candidates'
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)

        with pytest.raises(RuntimeError, match="missing 'candidates' array"):
            client.generate_answer("Test")

    def test_generate_answer_empty_candidates(self, httpx_mock):
        """Test that empty candidates array raises RuntimeError."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        httpx_mock.add_response(
            method="POST",
            url=api_url,
            json={"candidates": [], "usageMetadata": {"totalTokenCount": 10}},
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)

        with pytest.raises(RuntimeError, match="missing 'candidates' array"):
            client.generate_answer("Test")

    def test_generate_answer_missing_content(self, httpx_mock):
        """Test that missing 'content' raises RuntimeError."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        httpx_mock.add_response(
            method="POST",
            url=api_url,
            json={
                "candidates": [
                    {"finishReason": "STOP"}  # No 'content'
                ],
                "usageMetadata": {"totalTokenCount": 10},
            },
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)

        with pytest.raises(RuntimeError, match="missing 'content' field"):
            client.generate_answer("Test")

    def test_generate_answer_missing_parts(self, httpx_mock):
        """Test that missing 'parts' raises RuntimeError."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        httpx_mock.add_response(
            method="POST",
            url=api_url,
            json={
                "candidates": [
                    {
                        "content": {"role": "model"},  # No 'parts'
                        "finishReason": "STOP",
                    }
                ],
                "usageMetadata": {"totalTokenCount": 10},
            },
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)

        with pytest.raises(RuntimeError, match="missing 'parts' array"):
            client.generate_answer("Test")

    def test_generate_answer_empty_parts(self, httpx_mock):
        """Test that empty parts array raises RuntimeError."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        httpx_mock.add_response(
            method="POST",
            url=api_url,
            json={
                "candidates": [
                    {
                        "content": {"parts": [], "role": "model"},
                        "finishReason": "STOP",
                    }
                ],
                "usageMetadata": {"totalTokenCount": 10},
            },
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)

        with pytest.raises(RuntimeError, match="missing 'parts' array"):
            client.generate_answer("Test")

    def test_generate_answer_missing_text(self, httpx_mock):
        """Test that missing 'text' in part raises RuntimeError."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        httpx_mock.add_response(
            method="POST",
            url=api_url,
            json={
                "candidates": [
                    {
                        "content": {
                            "parts": [{}],
                            "role": "model",
                        },  # Empty part, no 'text'
                        "finishReason": "STOP",
                    }
                ],
                "usageMetadata": {"totalTokenCount": 10},
            },
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)

        with pytest.raises(RuntimeError, match="missing 'text' field"):
            client.generate_answer("Test")

    def test_generate_answer_safety_blocked(self, httpx_mock):
        """Test that SAFETY finish reason raises RuntimeError."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        httpx_mock.add_response(
            method="POST",
            url=api_url,
            json={
                "candidates": [
                    {
                        "content": {"parts": [{"text": ""}], "role": "model"},
                        "finishReason": "SAFETY",
                    }
                ],
                "usageMetadata": {"totalTokenCount": 10},
            },
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)

        with pytest.raises(RuntimeError, match="blocked content.*SAFETY"):
            client.generate_answer("Test")

    def test_generate_answer_recitation_blocked(self, httpx_mock):
        """Test that RECITATION finish reason raises RuntimeError."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        httpx_mock.add_response(
            method="POST",
            url=api_url,
            json={
                "candidates": [
                    {
                        "content": {"parts": [{"text": ""}], "role": "model"},
                        "finishReason": "RECITATION",
                    }
                ],
                "usageMetadata": {"totalTokenCount": 10},
            },
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)

        with pytest.raises(RuntimeError, match="blocked content.*RECITATION"):
            client.generate_answer("Test")

    def test_generate_answer_prohibited_content_blocked(self, httpx_mock):
        """Test that PROHIBITED_CONTENT finish reason raises RuntimeError."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        httpx_mock.add_response(
            method="POST",
            url=api_url,
            json={
                "candidates": [
                    {
                        "content": {"parts": [{"text": ""}], "role": "model"},
                        "finishReason": "PROHIBITED_CONTENT",
                    }
                ],
                "usageMetadata": {"totalTokenCount": 10},
            },
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)

        with pytest.raises(RuntimeError, match="blocked content.*PROHIBITED_CONTENT"):
            client.generate_answer("Test")

    def test_generate_answer_unexpected_tool_call(self, httpx_mock):
        """Test that UNEXPECTED_TOOL_CALL finish reason raises informative RuntimeError."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        httpx_mock.add_response(
            method="POST",
            url=api_url,
            json={
                "candidates": [
                    {
                        "finishReason": "UNEXPECTED_TOOL_CALL",
                        # Note: No 'content' field when tool call fails
                        "index": 0,
                    }
                ],
                "usageMetadata": {"totalTokenCount": 10},
            },
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)

        with pytest.raises(
            RuntimeError,
            match="encountered unexpected tool call.*UNEXPECTED_TOOL_CALL.*"
            "system prompt references tools",
        ):
            client.generate_answer("Test")

    def test_generate_answer_max_tokens(self, httpx_mock):
        """Test that MAX_TOKENS finish reason raises informative RuntimeError."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        httpx_mock.add_response(
            method="POST",
            url=api_url,
            json={
                "candidates": [
                    {
                        "content": {
                            "parts": [{"text": "Partial response that was cut o"}],
                            "role": "model",
                        },
                        "finishReason": "MAX_TOKENS",
                    }
                ],
                "usageMetadata": {"totalTokenCount": 10},
            },
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)

        with pytest.raises(
            RuntimeError,
            match="exceeded maximum token limit.*MAX_TOKENS.*"
            "shorter prompt or.*larger context window",
        ):
            client.generate_answer("Test")

    def test_generate_answer_unknown_finish_reason(self, httpx_mock):
        """Test that unknown finish reasons raise informative RuntimeError."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        httpx_mock.add_response(
            method="POST",
            url=api_url,
            json={
                "candidates": [
                    {
                        "content": {"parts": [{"text": "Some text"}], "role": "model"},
                        "finishReason": "SOME_FUTURE_REASON",
                    }
                ],
                "usageMetadata": {"totalTokenCount": 10},
            },
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)

        with pytest.raises(
            RuntimeError,
            match="unexpected finish reason.*SOME_FUTURE_REASON.*incomplete or invalid",
        ):
            client.generate_answer("Test")

    def test_generate_answer_malformed_json(self, httpx_mock):
        """Test that malformed JSON raises RuntimeError."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        httpx_mock.add_response(
            method="POST",
            url=api_url,
            content=b"{ invalid json",
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)

        with pytest.raises(RuntimeError, match="Failed to parse Gemini response JSON"):
            client.generate_answer("Test")


class TestTokenUsageExtraction:
    """Test suite for token usage extraction."""

    def test_extract_token_usage_complete(self, httpx_mock):
        """Test extraction of complete token usage metadata."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        httpx_mock.add_response(
            method="POST",
            url=api_url,
            json={
                "candidates": [
                    {
                        "content": {"parts": [{"text": "Response"}], "role": "model"},
                        "finishReason": "STOP",
                    }
                ],
                "usageMetadata": {
                    "promptTokenCount": 150,
                    "candidatesTokenCount": 75,
                    "totalTokenCount": 225,
                },
            },
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)
        response = client.generate_answer("Test")

        assert response.tokens_used == 225
        assert response.prompt_tokens == 150
        assert response.completion_tokens == 75

    def test_extract_token_usage_missing_metadata(self, httpx_mock, caplog):
        """Test graceful handling of missing usageMetadata."""
        caplog.set_level(logging.WARNING)

        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        httpx_mock.add_response(
            method="POST",
            url=api_url,
            json={
                "candidates": [
                    {
                        "content": {"parts": [{"text": "Response"}], "role": "model"},
                        "finishReason": "STOP",
                    }
                ],
                # No usageMetadata
            },
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)
        response = client.generate_answer("Test")

        # Should default to 0
        assert response.tokens_used == 0
        assert response.prompt_tokens == 0
        assert response.completion_tokens == 0

        # Should log warning
        assert "missing 'usageMetadata'" in caplog.text
        assert "gemini-2.0-flash-exp" in caplog.text

    def test_extract_token_usage_partial_metadata(self, httpx_mock):
        """Test handling of partial token usage metadata."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        httpx_mock.add_response(
            method="POST",
            url=api_url,
            json={
                "candidates": [
                    {
                        "content": {"parts": [{"text": "Response"}], "role": "model"},
                        "finishReason": "STOP",
                    }
                ],
                "usageMetadata": {
                    "promptTokenCount": 100,
                    # Missing candidatesTokenCount and totalTokenCount
                },
            },
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)
        response = client.generate_answer("Test")

        # Should calculate total from prompt + candidates (0)
        assert response.prompt_tokens == 100
        assert response.completion_tokens == 0
        assert response.tokens_used == 100


class TestErrorDetailExtraction:
    """Test suite for error detail extraction."""

    def test_extract_error_detail_with_message(self, httpx_mock):
        """Test extraction of error message from API response."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        httpx_mock.add_response(
            method="POST",
            url=api_url,
            status_code=400,
            json={"error": {"message": "Invalid request: missing required field"}},
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)

        with pytest.raises(RuntimeError) as exc_info:
            client.generate_answer("Test")

        error_msg = str(exc_info.value)
        assert "Invalid request: missing required field" in error_msg

    def test_extract_error_detail_without_message(self, httpx_mock):
        """Test fallback when error message is unavailable."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        httpx_mock.add_response(
            method="POST",
            url=api_url,
            status_code=500,
            content=b"Internal Server Error",
        )

        client = GeminiClient(model_name, "AIza-test123", TEST_SYSTEM_PROMPT)

        with pytest.raises(RuntimeError) as exc_info:
            client.generate_answer("Test")

        error_msg = str(exc_info.value)
        assert "HTTP 500" in error_msg


class TestSecurityAndLogging:
    """Test suite for security and logging requirements."""

    def test_api_key_never_logged_on_error(self, httpx_mock, caplog):
        """Test that API key is NEVER logged in error messages."""
        caplog.set_level(logging.ERROR)

        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        httpx_mock.add_response(
            method="POST",
            url=api_url,
            status_code=401,
            json={"error": {"message": "Invalid API key"}},
        )

        client = GeminiClient(model_name, "AIza-secret456", TEST_SYSTEM_PROMPT)

        with pytest.raises(RuntimeError):
            client.generate_answer("Test")

        # Should NEVER log API key
        assert "AIza-secret456" not in caplog.text
        assert "secret" not in caplog.text

    def test_api_key_never_in_exception_message(self, httpx_mock):
        """Test that API key is not included in exception messages."""
        model_name = "gemini-2.0-flash-exp"
        api_url = f"{GEMINI_API_BASE_URL}/models/{model_name}:generateContent"

        httpx_mock.add_response(
            method="POST",
            url=api_url,
            status_code=403,
            json={"error": {"message": "Forbidden"}},
        )

        client = GeminiClient(model_name, "AIza-secret789", TEST_SYSTEM_PROMPT)

        with pytest.raises(RuntimeError) as exc_info:
            client.generate_answer("Test")

        error_msg = str(exc_info.value)
        assert "AIza-secret789" not in error_msg
        assert "secret" not in error_msg
